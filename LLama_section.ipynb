{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('ak',): 0, ('aku',): 1, ('aku', '</w>'): 2, ('s',): 3, ('su',): 4, ('suk',): 5, ('suka',): 6, ('suka', '</w>'): 7, ('d',): 8, ('di',): 9, ('dim',): 10, ('dima',): 11, ('dima', 'n'): 12, ('dimana',): 13, ('dimana', '</w>'): 14, ('n',): 15, ('na',): 16, ('nas',): 17, ('nasi',): 18, ('nasi</w>',): 19, ('dim', 'ak'): 20, ('dim', 'aka'): 21, ('dimakan',): 22, ('dimakan', '</w>'): 23, ('a',): 24, ('ay',): 25, ('aya',): 26, ('ayam',): 27, ('ayam', '</w>'): 28, ('m',): 29, ('mak',): 30, ('maka',): 31, ('makan',): 32, ('makan</w>',): 33, ('dime',): 34, ('dimej',): 35, ('dimeja',): 36, ('dimeja', '</w>'): 37}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed()\n",
    "corpus = [[\"aku\", \"suka\", \"dimana\", \"nasi\"], [\"nasi\", \"dimakan\", \"ayam\"], [\"makan\", \"dimeja\" ,\"makan\"]]\n",
    "def tokenizer(corpus):\n",
    "    vocab = {}\n",
    "    for kalimat in corpus:\n",
    "        for kata in kalimat:\n",
    "            char = list(kata) + [\"</w>\"]\n",
    "            char = tuple(char)\n",
    "            if char in vocab:\n",
    "                vocab[char] += 1\n",
    "            else:\n",
    "                vocab[char] = 1\n",
    "    while True:\n",
    "        pair_freq = {}\n",
    "        for token, freq in vocab.items():\n",
    "            for i in range(len(token) - 1):\n",
    "                pair = (token[i], token[i+1])\n",
    "                if pair in pair_freq:\n",
    "                    pair_freq[pair] += freq\n",
    "                else:\n",
    "                    pair_freq[pair] = freq\n",
    "        best_value = max(pair_freq.values())\n",
    "        best_pair = max(pair_freq, key=pair_freq.get)\n",
    "\n",
    "        if best_value < 2:\n",
    "            break\n",
    "\n",
    "        new_vocab = {}\n",
    "        for token, freq in vocab.items():\n",
    "            new_token = []\n",
    "            i = 0\n",
    "            while i < len(token):\n",
    "                if i < len(token) - 1 and (token[i], token[i+1]) == best_pair:\n",
    "                    new_token.append(token[i] + token[i+1])\n",
    "                    new_vocab[tuple(new_token)] = freq\n",
    "                    i += 2\n",
    "\n",
    "                else:\n",
    "                    new_token.append(token[i])\n",
    "                    i += 1\n",
    "                new_vocab[tuple(new_token)] = freq\n",
    "\n",
    "        vocab = new_vocab\n",
    "        vocab_index = {}\n",
    "        for i, token in enumerate(vocab.keys()):\n",
    "            vocab_index[token] = i\n",
    "        \n",
    "    return vocab_index\n",
    "\n",
    "\n",
    "vocab_index = tokenizer(corpus)\n",
    "print(vocab_index)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "def urut_vocab(vocab_index):\n",
    "    token_set = set()\n",
    "    for token_tuple in vocab_index.keys():\n",
    "        for t in token_tuple:\n",
    "            token_set.add(t)\n",
    "            \n",
    "    vocab_dict = {token: idx for idx, token in enumerate(sorted(token_set))}\n",
    "    vocab_dict[\"[UNK]\"] = len(vocab_dict)  # optional: token unknown\n",
    "    return vocab_dict\n",
    "\n",
    "vocab = urut_vocab(vocab_index)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 0, 30, 0, 13, 0, 26], [26, 11, 31, 1, 22, 0, 7, 0], [21, 16, 0, 21]]\n"
     ]
    }
   ],
   "source": [
    "def encode_word(word, vocab):\n",
    "    tokens = list(word) + [\"</w>\"]\n",
    "    while True:\n",
    "        merged = False\n",
    "        for i in range(len(tokens)-1):\n",
    "            pair = tokens[i] + tokens[i+1]\n",
    "            if pair in vocab:\n",
    "                tokens = tokens[:i] + [pair] + tokens[i+2:]\n",
    "                merged = True\n",
    "                break\n",
    "        if not merged:\n",
    "            break\n",
    "\n",
    "    token_ids = []\n",
    "    for t in tokens:\n",
    "        if t in vocab:\n",
    "            token_ids.append(vocab[t])\n",
    "        else:\n",
    "            for c in t:\n",
    "                if c in vocab:\n",
    "                    token_ids.append(vocab[c])\n",
    "                else:\n",
    "                    token_ids.append(vocab['[UNK]'])\n",
    "    return token_ids\n",
    "\n",
    "def encode_corpus(corpus, vocab):\n",
    "    encoded = []\n",
    "    for sentence in corpus: \n",
    "        encoded_sentence = []\n",
    "        for word in sentence:\n",
    "            encoded_sentence.extend(encode_word(word, vocab))\n",
    "        encoded.append(encoded_sentence)\n",
    "    return encoded\n",
    "\n",
    "token = encode_corpus(corpus, vocab)\n",
    "print(token)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed()\n",
    "\n",
    "def padding(token,max_len, padding_value = 0):\n",
    "    token = list(token)\n",
    "    padded =np.full((len(token),max_len), padding_value)\n",
    "\n",
    "    for i , token in enumerate(token): \n",
    "        p_token = len(token)\n",
    "        padded[i, :p_token] = token\n",
    "    return padded \n",
    "max_len = max(len(i) for i in token)\n",
    "token = padding(token,max_len)\n",
    "print(token.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [token[i:i\u001b[38;5;241m+\u001b[39mbatch_size]  \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(token),batch_size)]\n\u001b[0;32m      4\u001b[0m batch \u001b[38;5;241m=\u001b[39m buat_batch(token)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# def buat_batch(token, batch_size = 3):\n",
    "#     return [token[i:i+batch_size]  for i in range(0,len(token),batch_size)]\n",
    "\n",
    "# batch = buat_batch(token)\n",
    "# print(batch.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "d = 16\n",
    "e_matriks = np.array(np.random.rand(len(vocab), d))\n",
    "embedding = e_matriks[token]\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(embedding)\n",
    "eps = 1e-6\n",
    "rms = np.sqrt(np.mean(x**2, axis=1, keepdims=True) + eps )\n",
    "norm = x/rms\n",
    "hasil = norm * 0.5\n",
    "print(hasil.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rope(Q,K):\n",
    "    assert Q.shape == K.shape\n",
    "    batch, num_group, num_head, seq_len, head_dim= Q.shape\n",
    "    assert head_dim % 2== 0\n",
    "    set_dim = head_dim//2\n",
    "    freq   = 1/ 1000 **(np.arange(0,set_dim)/set_dim)\n",
    "    pos = np.arange(seq_len)\n",
    "    angle = np.outer(pos,freq)\n",
    "    sin = np.sin(angle)[None,None,None,:,:]\n",
    "    cos = np.cos(angle)[None,None,None,:,:]\n",
    "\n",
    "    def rotate(x):\n",
    "        X1 = x[...,::2]\n",
    "        X2 = x[...,1::2]\n",
    "        rotasi = np.concatenate([X1*cos - X2*sin, X1*sin + X2*cos], axis=-1)\n",
    "        return rotasi\n",
    "\n",
    "    Q = rotate(Q)\n",
    "    \n",
    "    K = rotate(K)\n",
    "    return (Q,K)    \n",
    "\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    x = x - np.max(x, axis=axis, keepdims=True)  # Untuk stabilitas numerik\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 2, 8, 8)\n",
      "(3, 2, 2, 8, 8)\n",
      "(3, 8, 2, 2, 4)\n",
      "(3, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "num_group = 2\n",
    "num_head = 2\n",
    "head_dim = 4 \n",
    "\n",
    "\n",
    "wq = np.random.randn(d,d)\n",
    "wk = np.random.randn(d,d)\n",
    "wv = np.random.randn(d,d)\n",
    "\n",
    "Q = hasil @ wq\n",
    "K = hasil @ wk\n",
    "V = hasil @ wv\n",
    "\n",
    " \n",
    "Q = Q.reshape(3,8,num_group, num_head, head_dim)\n",
    "K = K.reshape(3,8,num_group, num_head, head_dim)\n",
    "V = V.reshape(3,8,num_group, num_head, head_dim)\n",
    "\n",
    "Q = Q.transpose(0,2,3,1,4)\n",
    "K = K.transpose(0,2,3,1,4)\n",
    "V = V.transpose(0,2,3,1,4)\n",
    "\n",
    "\n",
    "Q,K = rope(Q, K)\n",
    "\n",
    "\n",
    "\n",
    "scores = np.einsum('bghqd, bghkd->bghqk', Q,K)\n",
    "print (scores.shape)\n",
    "b,g,h,s,s = scores.shape\n",
    "mask = np.tril(np.ones((s,s), dtype=bool))\n",
    "mask = mask[None, None, None, :,:]\n",
    "scores = np.where(mask, scores, -1e9)\n",
    "\n",
    "scores = scores/ np.sqrt(head_dim)\n",
    "weight =  softmax(scores, axis=-1)\n",
    "output = np.einsum(\"bghqk, bghkd -> bghqd\", weight, V)\n",
    "print (weight.shape)\n",
    "output = output.transpose(0,3,1,2,4)\n",
    "print(output.shape)\n",
    "b, s, g,h,d = output.shape\n",
    "output = output.reshape(b,s,g*h*d)\n",
    "print(output.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "def RMSnorm(x, gamma = 0.5):\n",
    "   x = np.array(x)\n",
    "   rms = np.sqrt(np.mean(x**2, axis=-1, keepdims=True))\n",
    "   norm = gamma * x / rms\n",
    "   return norm\n",
    "\n",
    "add1 =output +  embedding\n",
    "norm = RMSnorm(add1)\n",
    "print(norm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8, 64) before\n",
      "(3, 8, 32) after\n",
      "(3, 8, 16) linear\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def swish(x):\n",
    "    return x * sigmoid(x)    \n",
    "\n",
    "def SwingGlu(x1,x2):\n",
    "    return  x2 * swish(x1) \n",
    "matmul = np.matmul\n",
    "x = np.array(norm)\n",
    "dx = x.shape[1]\n",
    "dx = dx *4\n",
    "b, s,d = norm.shape\n",
    "w1 = np.random.randn( d, s, 4*d)\n",
    "\n",
    "\n",
    "# Logits = matmul(x, w1) + b1\n",
    "Logits = np.einsum(\"hij,jik->hik\", x,w1)\n",
    "b1 = np.random.randn(*Logits.shape)\n",
    "Logits = Logits + b1\n",
    "print(Logits.shape ,\"before\")\n",
    "belah = Logits.shape[-1]//2\n",
    "x1 = Logits[:,:, :belah]\n",
    "x2 = Logits[:,:,belah:]\n",
    "logits = SwingGlu(x1,x2)\n",
    "print(logits.shape,\"after\")\n",
    "w2 = np.random.randn(logits.shape[2],s,logits.shape[2]//2 )\n",
    "linear_out = np.einsum(\"hij,jik->hik\",logits, w2)\n",
    "b2 = np.random.randn(*linear_out.shape)\n",
    "linear_out = linear_out + b2\n",
    "print(linear_out.shape,\"linear\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "add2 = linear_out + add1\n",
    "nnorm = RMSnorm(add2)\n",
    "print(nnorm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8, 32)\n"
     ]
    }
   ],
   "source": [
    "Linear_w= np.random.randn(d, len(vocab))\n",
    "b = np.random.randn(len(vocab))\n",
    "last_linear = np.einsum( \"abc,ce->abe\", nnorm, Linear_w)\n",
    "print(last_linear.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8, 32)\n",
      "(3, 8)\n"
     ]
    }
   ],
   "source": [
    "model = softmax(last_linear)\n",
    "print(model.shape)\n",
    "\n",
    "sums= np.sum(model, axis =-1)\n",
    "print(sums.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next token ID: 9\n"
     ]
    }
   ],
   "source": [
    "next_token_probs = probs[:, -1, :]  # ambil posisi terakhir\n",
    "next_token_id = np.argmax(next_token_probs, axis=-1)[0]  # ambil token id prediksi\n",
    "next_token = id2word[next_token_id]\n",
    "print(\"Predicted next token:\", next_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0 30  0 13  0 26  0]\n",
      " [26 11 31  1 22  0  7  0]\n",
      " [21 16  0 21  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
